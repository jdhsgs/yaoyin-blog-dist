<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>语义分割cnn | yaoyin&#39;s Blog</title>
    <meta name="generator" content="VuePress 1.8.2">
    <link rel="icon" href="./favicon.ico">
    <link rel="stylesheet" href="./css/style.css">
    <script rel="stylesheet" type="text/javascript" src="./js/main.js"></script>
    <meta name="description" content="姚寅的个人小站">
    <meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no">
    
    <link rel="preload" href="./assets/css/0.styles.e842a6eb.css" as="style"><link rel="preload" href="./assets/js/app.efa3ac42.js" as="script"><link rel="preload" href="./assets/js/3.88a32308.js" as="script"><link rel="preload" href="./assets/js/1.e463e428.js" as="script"><link rel="preload" href="./assets/js/14.b6c41929.js" as="script"><link rel="prefetch" href="./assets/js/10.e9337950.js"><link rel="prefetch" href="./assets/js/11.3c361c4d.js"><link rel="prefetch" href="./assets/js/12.6775a63c.js"><link rel="prefetch" href="./assets/js/13.19af0b74.js"><link rel="prefetch" href="./assets/js/15.57c8bab0.js"><link rel="prefetch" href="./assets/js/16.660bb2ef.js"><link rel="prefetch" href="./assets/js/17.65eeccb7.js"><link rel="prefetch" href="./assets/js/18.14a41994.js"><link rel="prefetch" href="./assets/js/19.835889b7.js"><link rel="prefetch" href="./assets/js/20.ae4d1c05.js"><link rel="prefetch" href="./assets/js/21.c08b29ef.js"><link rel="prefetch" href="./assets/js/22.c20f65b0.js"><link rel="prefetch" href="./assets/js/23.59a9ca75.js"><link rel="prefetch" href="./assets/js/24.43100cfb.js"><link rel="prefetch" href="./assets/js/25.2e5adb0d.js"><link rel="prefetch" href="./assets/js/26.59e9cff3.js"><link rel="prefetch" href="./assets/js/4.497aab32.js"><link rel="prefetch" href="./assets/js/5.05cc3fc3.js"><link rel="prefetch" href="./assets/js/6.4c690b16.js"><link rel="prefetch" href="./assets/js/7.2ae81801.js"><link rel="prefetch" href="./assets/js/8.670223b0.js"><link rel="prefetch" href="./assets/js/9.168b60ba.js">
    <link rel="stylesheet" href="./assets/css/0.styles.e842a6eb.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container no-sidebar" data-v-1156296a><div data-v-1156296a><div id="loader-wrapper" class="loading-wrapper" data-v-d48f4d20 data-v-1156296a data-v-1156296a><div class="loader-main" data-v-d48f4d20><div data-v-d48f4d20></div><div data-v-d48f4d20></div><div data-v-d48f4d20></div><div data-v-d48f4d20></div></div> <!----> <!----></div> <div class="password-shadow password-wrapper-out" style="display:none;" data-v-4e82dffc data-v-1156296a data-v-1156296a><h3 class="title" data-v-4e82dffc data-v-4e82dffc>yaoyin's Blog</h3> <p class="description" data-v-4e82dffc data-v-4e82dffc>姚寅的个人小站</p> <label id="box" class="inputBox" data-v-4e82dffc data-v-4e82dffc><input type="password" value="" data-v-4e82dffc> <span data-v-4e82dffc>Konck! Knock!</span> <button data-v-4e82dffc>OK</button></label> <div class="footer" data-v-4e82dffc data-v-4e82dffc><span data-v-4e82dffc><i class="iconfont reco-theme" data-v-4e82dffc></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-4e82dffc>vuePress-theme-reco</a></span> <span data-v-4e82dffc><i class="iconfont reco-copyright" data-v-4e82dffc></i> <a data-v-4e82dffc><span data-v-4e82dffc>YAOYIN</span>
            
          <span data-v-4e82dffc>2021 - </span>
          2022
        </a></span></div></div> <div class="hide" data-v-1156296a><header class="navbar" data-v-1156296a><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/./" class="home-link router-link-active"><img src="./logo.png" alt="yaoyin's Blog" class="logo"> <span class="site-name">yaoyin's Blog</span></a> <div class="links"><div class="color-picker"><a class="color-button"><i class="iconfont reco-color"></i></a> <div class="color-picker-menu" style="display:none;"><div class="mode-options"><h4 class="title">Choose mode</h4> <ul class="color-mode-options"><li class="dark">dark</li><li class="auto active">auto</li><li class="light">light</li></ul></div></div></div> <div class="search-box"><i class="iconfont reco-search"></i> <input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/./" class="nav-link"><i class="iconfont reco-home"></i>
  首页
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-category"></i>
      分类
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/./categories/环境配置/" class="nav-link"><i class="undefined"></i>
  环境配置
</a></li><li class="dropdown-item"><!----> <a href="/./categories/python学习/" class="nav-link"><i class="undefined"></i>
  python学习
</a></li><li class="dropdown-item"><!----> <a href="/./categories/神经网络/" class="nav-link"><i class="undefined"></i>
  神经网络
</a></li><li class="dropdown-item"><!----> <a href="/./categories/算法/" class="nav-link"><i class="undefined"></i>
  算法
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-category"></i>
      技术汇总
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>入门及工具</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/./note/cnn/network/" aria-current="page" class="nav-link router-link-exact-active router-link-active"><i class="undefined"></i>
  cnn入门
</a></li></ul></li></ul></div></div><div class="nav-item"><a href="/./timeline/" class="nav-link"><i class="iconfont reco-date"></i>
  时间线
</a></div><div class="nav-item"><a href="https://github.com/jdhsgs" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="iconfont reco-github"></i>
  GitHub
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div><div class="nav-item"><a href="/./tag/" class="nav-link"><i class="iconfont reco-tag"></i>
  标签
</a></div> <!----></nav></div></header> <div class="sidebar-mask" data-v-1156296a></div> <aside class="sidebar" data-v-1156296a><div class="personal-info-wrapper" data-v-828910c6 data-v-1156296a><img src="./avatar.png" alt="author-avatar" class="personal-img" data-v-828910c6> <h3 class="name" data-v-828910c6>
    YAOYIN
  </h3> <div class="num" data-v-828910c6><div data-v-828910c6><h3 data-v-828910c6>16</h3> <h6 data-v-828910c6>Articles</h6></div> <div data-v-828910c6><h3 data-v-828910c6>5</h3> <h6 data-v-828910c6>Tags</h6></div></div> <ul class="social-links" data-v-828910c6></ul> <hr data-v-828910c6></div> <nav class="nav-links"><div class="nav-item"><a href="/./" class="nav-link"><i class="iconfont reco-home"></i>
  首页
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-category"></i>
      分类
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/./categories/环境配置/" class="nav-link"><i class="undefined"></i>
  环境配置
</a></li><li class="dropdown-item"><!----> <a href="/./categories/python学习/" class="nav-link"><i class="undefined"></i>
  python学习
</a></li><li class="dropdown-item"><!----> <a href="/./categories/神经网络/" class="nav-link"><i class="undefined"></i>
  神经网络
</a></li><li class="dropdown-item"><!----> <a href="/./categories/算法/" class="nav-link"><i class="undefined"></i>
  算法
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-category"></i>
      技术汇总
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>入门及工具</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/./note/cnn/network/" aria-current="page" class="nav-link router-link-exact-active router-link-active"><i class="undefined"></i>
  cnn入门
</a></li></ul></li></ul></div></div><div class="nav-item"><a href="/./timeline/" class="nav-link"><i class="iconfont reco-date"></i>
  时间线
</a></div><div class="nav-item"><a href="https://github.com/jdhsgs" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="iconfont reco-github"></i>
  GitHub
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div><div class="nav-item"><a href="/./tag/" class="nav-link"><i class="iconfont reco-tag"></i>
  标签
</a></div> <!----></nav> <!----> </aside> <div class="password-shadow password-wrapper-in" style="display:none;" data-v-4e82dffc data-v-1156296a><h3 class="title" data-v-4e82dffc data-v-4e82dffc>语义分割cnn</h3> <!----> <label id="box" class="inputBox" data-v-4e82dffc data-v-4e82dffc><input type="password" value="" data-v-4e82dffc> <span data-v-4e82dffc>Konck! Knock!</span> <button data-v-4e82dffc>OK</button></label> <div class="footer" data-v-4e82dffc data-v-4e82dffc><span data-v-4e82dffc><i class="iconfont reco-theme" data-v-4e82dffc></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-4e82dffc>vuePress-theme-reco</a></span> <span data-v-4e82dffc><i class="iconfont reco-copyright" data-v-4e82dffc></i> <a data-v-4e82dffc><span data-v-4e82dffc>YAOYIN</span>
            
          <span data-v-4e82dffc>2021 - </span>
          2022
        </a></span></div></div> <div data-v-1156296a><main class="page"><section><div class="page-title"><h1 class="title">语义分割cnn</h1> <div data-v-1ff7123e><i class="iconfont reco-account" data-v-1ff7123e><span data-v-1ff7123e>YAOYIN</span></i> <i class="iconfont reco-date" data-v-1ff7123e><span data-v-1ff7123e>12/8/2021</span></i> <!----> <i class="tags iconfont reco-tag" data-v-1ff7123e><span class="tag-item" data-v-1ff7123e>cnn</span></i></div></div> <div class="theme-reco-content content__default"><h1 id="网络"><a href="#网络" class="header-anchor">#</a> 网络</h1> <h1 id="cnn"><a href="#cnn" class="header-anchor">#</a> cnn</h1> <p>是一种专门用来处理<strong>具有类似网格结构的数据的神经网络</strong>。<strong>卷积网络</strong>是指那些至少在网络的一层中使用卷积运算来替代一般的矩阵乘法运算的神经网络。</p> <p><img src="https://img-blog.csdnimg.cn/20191116145026770.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNzc2Mzg3MA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> <p><em>上图为DNN神经网络图，DNN内部的神经网络层可以分为三类，<strong>输入层，隐藏层和输出层</strong>，一般来说第一层是输出层，最后一层是输出层，而中间的层数都是隐藏层。</em></p> <p><img src="https://img-blog.csdnimg.cn/2019111615080290.png" alt="在这里插入图片描述"></p> <p>总结</p> <p>1.<strong>DNN</strong>是一种最简单的神经网络。各个神经元分别属于不同的层，每个神经元和前一层的所有神经元相连接，信号从输入层向输出层单向传播</p> <p>2.<strong>CNN</strong>是一种通过卷积计算的前馈神经网络，其是受生物学上的感受野机制提出的，具有平移不变性，使用卷积核，最大的应用了局部信息，保留了平面结构信息</p> <p>3.DNN以向量形式输入，未考虑平面的结构信息，而在图像领域和自然语言处理领域，平面信息很重要，因此CNN比DNN处理结果更好。</p> <p><strong>由于DNN、CNN的输入、输出长度固定，而自然语言处理中的语句长度通常不固定，所以DNN、CNN处理这种问题效率较低，且无法处理时序相关的序列问题.为了解决这些问题，出现了循环神经网络RNN</strong></p> <h2 id="cnn的五种结构"><a href="#cnn的五种结构" class="header-anchor">#</a> cnn的五种结构</h2> <h4 id="_1-输入层"><a href="#_1-输入层" class="header-anchor">#</a> 1.输入层</h4> <p>在处理图像的CNN中，输入层一般代表了<strong>一张图片的像素矩阵</strong>。可以用<strong>三维矩阵代表一张图片</strong>。三维矩阵的长和宽代表了图像的大小，而三维矩阵的深度代表了图像的色彩通道。比如<strong>黑白图片的深度为1，而在RGB色彩模式下，图像的深度为3。</strong></p> <h4 id="_2-卷积层"><a href="#_2-卷积层" class="header-anchor">#</a> 2.卷积层</h4> <p><strong>卷积层是CNN最重要的部分</strong>。它与传统全连接层不同，卷积层中每一个节点的输入只是上一层神经网络的一小块。<strong>卷积层被称为过滤器(filter)或者内核(kernel)，Tensorflow的官方文档中称这个部分为过滤器(filter)</strong>。</p> <p>【注意】在一个卷积层中，过滤器(filter)所处理的节点矩阵的长和宽都是由人工指定的，这个节点矩阵的尺寸也被称为过滤器尺寸。<strong>常用的尺寸有3x3或5x5</strong>，而过滤层处理的矩阵深度和当前处理的神经层网络节点矩阵的深度一致。</p> <p><img src="https://img-blog.csdnimg.cn/20191116154816709.gif" alt="在这里插入图片描述"></p> <p>卷积的过程</p> <p><img src="https://img-blog.csdnimg.cn/2019111615502886.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNzc2Mzg3MA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> <h4 id="_3-池化层"><a href="#_3-池化层" class="header-anchor">#</a> 3.池化层</h4> <p>池化层不会改变三维矩阵的深度，但是它<strong>可以缩小矩阵的大小</strong>。</p> <p>通过池化层，可以进一步缩小最后全连接层中节点的个数，从而达到减少整个神经网络参数的目的。使用池化层既可以加快计算速度也可以防止过拟合。池化层filter的计算不是节点的加权和，而是采用最大值或者平均值计算。使用最大值操作的池化层被称之为最大池化层（max pooling）（最大池化层是使用的最多的磁化层结构）。使用平均值操作的池化层被称之为平均池化层（mean pooling）。
<img src="https://img-blog.csdnimg.cn/20191116160351379.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNzc2Mzg3MA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> <p><img src="https://img-blog.csdnimg.cn/20191116160420689.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNzc2Mzg3MA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> <h4 id="_4-全连接层"><a href="#_4-全连接层" class="header-anchor">#</a> 4.全连接层</h4> <p>在经过多轮卷积层和池化层的处理之后，在CNN的最后一般会由1到2个全连接层来给出最后的分类结果。</p> <p>经过几轮卷积层和池化层的处理之后，可以认为图像中的信息已经被抽象成了信息含量更高的特征。</p> <p>我们可以将卷积层和池化层看成自动图像特征提取的过程。在提取完成之后，仍然需要使用全连接层来完成分类任务。</p> <h4 id="_5-softmax层"><a href="#_5-softmax层" class="header-anchor">#</a> 5.Softmax层</h4> <p>通过Softmax层，可以得到当前样例属于不同种类的概率分布问题。</p> <h1 id="fcn"><a href="#fcn" class="header-anchor">#</a> FCN</h1> <h2 id="cnn与fcn的比较"><a href="#cnn与fcn的比较" class="header-anchor">#</a> CNN与FCN的比较</h2> <p>CNN: 在传统的CNN网络中，在最后的卷积层之后会连接上若干个全连接层，将卷积层产生的特征图（feature map）映射成为一个固定长度的特征向量。一般的CNN结构适用于图像级别的分类和回归任务，因为它们最后都期望得到输入图像的分类的概率，如ALexNet网络最后输出一个1000维的向量表示输入图像属于每一类的概率。
<img src="https://img-blog.csdnimg.cn/20190727205043126.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNzYwNzY3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> <p>在CNN中, 猫的图片输入到AlexNet, 得到一个长为1000的输出向量, 表示输入图像属于每一类的概率, 其中在“tabby cat”这一类统计概率最高, 用来做分类任务。</p> <p><strong>FCN:</strong> FCN是对图像进行像素级的分类（也就是每个像素点都进行分类），从而解决了语义级别的图像分割问题。</p> <p>与上面介绍的经典CNN在卷积层使用全连接层得到固定长度的特征向量进行分类不同，FCN可以接受任意尺寸的输入图像</p> <p>采用反卷积层对最后一个卷基层的特征图（feature map）进行上采样，使它恢复到输入图像相同的尺寸，从而可以对每一个像素都产生一个预测，同时保留了原始输入图像中的空间信息，最后奇偶在上采样的特征图进行像素的分类</p> <p><img src="https://img-blog.csdnimg.cn/20190727205145371.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNzYwNzY3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> <p>简单的说，FCN与CNN的区别在于FCN把CNN最后的全连接层换成卷积层，其输出的是一张已经标记好的图，而不是一个概率值。</p> <h2 id="fcn上采样讲解"><a href="#fcn上采样讲解" class="header-anchor">#</a> FCN上采样讲解</h2> <p>FCN网络一般是用来对图像进行语义分割的，于是就需要对图像上的各个像素进行分类，这就需要一个上采样将最后得到的输出上采样到原图的大小。上采样对于低分辨率的特征图，常常采用上采样的方式将它还原高分辨率，这里陈述上采样的三种方法</p> <h3 id="_1-双线性插值上采样"><a href="#_1-双线性插值上采样" class="header-anchor">#</a> 1.双线性插值上采样</h3> <p>单线性插值（一个方向上）就是知道两个点的值，并将两点连成一条直线，来确定中间的点的值</p> <h3 id="_2-反卷积上采样"><a href="#_2-反卷积上采样" class="header-anchor">#</a> 2.反卷积上采样</h3> <p><strong>怎样上采样：</strong> 普通的卷积操作，会使得分辨率降低，如下图3<em>3的卷积核去卷积4</em>4得到2*2的输出。</p> <p><img src="https://img-blog.csdnimg.cn/20190727205525518.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNzYwNzY3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> <p>上采样的过程也是卷积，那么怎么会得到分辨率提高呢？之前我们看卷积时有个保持输出与输入同分辨率的方法就是周围补0。</p> <p><img src="https://img-blog.csdnimg.cn/20190727205545284.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNzYwNzY3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> <p>其实上面这种补0的方法事有问题的，你想一下，只在四周补0会导致最边上的信息不太好，那我们把这个信息平均下，在每个像素与像素之间补0，如下图所示：</p> <p><img src="https://img-blog.csdnimg.cn/20190727205607141.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNzYwNzY3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> <h3 id="_3-反池化上采样"><a href="#_3-反池化上采样" class="header-anchor">#</a> 3.反池化上采样</h3> <p>反池化可以用下图来理解，再池化时需要记录下池化的位置，反池化时把池化的位置直接还原，其他位置填0。</p> <p><img src="https://img-blog.csdnimg.cn/20190727205635411.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNzYwNzY3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> <p>上面三种方法各有优缺，双线性插值方法实现简单，无需训练；反卷积上采样需要训练，但能更好的还原特征图；</p> <h3 id="fcn的实现"><a href="#fcn的实现" class="header-anchor">#</a> FCN的实现</h3> <p><img src="https://img-blog.csdnimg.cn/20190728153344199.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNzYwNzY3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> <p><img src="https://img-blog.csdnimg.cn/20190728153423546.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNzYwNzY3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> <p>经过多次卷积后，图像的分辨率越来越低，为了从低分辨率的热图heatmap恢复到原图大小，以便对原图上每一个像素点进行分类预测，需要对热图heatmap进行反卷积，也就是上采样。论文中首先进行了一个上池化操作，再进行反卷积（上述所提到的上池化操作和反卷积操作，其实可以理解为上卷积操作），使得图像分辨率提高到原图大小。
<img src="https://img-blog.csdnimg.cn/20190728153507888.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNzYwNzY3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> <p><strong>跳级(strip)结构</strong>：对第5层的输出执行32倍的反卷积得到原图，得到的结果不是很精确，论文中同时执行了第4层和第3层输出的反卷积操作（分别需要16倍和8倍的上采样），再把这3个反卷积的结果图像融合，提升了结果的精确度：</p> <p><img src="https://img-blog.csdnimg.cn/2019072815355086.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNzYwNzY3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> <h3 id="fcn的实现过程"><a href="#fcn的实现过程" class="header-anchor">#</a> FCN的实现过程</h3> <p>用AlexNet，VGG16或者GoogleNet训练好的模型做初始化，在这个基础上做fine-tuning，只需在末尾加上upsampling，参数的学习还是利用CNN本身的反向传播原理</p> <h2 id="总结"><a href="#总结" class="header-anchor">#</a> 总结</h2> <p>FCN的卷积网络部分可以采用VGG、GoogleNet、AlexNet等作为前置基础网络，在这些的预训练基础上进行迁移学习与finetuning，对反卷积的结果跟对应的正向feature map进行叠加输出(这样做的目的是得到更加准确的像素级别分割)</p> <h2 id="基于深度学习的分割"><a href="#基于深度学习的分割" class="header-anchor">#</a> 基于深度学习的分割</h2> <h3 id="_1-vggnet"><a href="#_1-vggnet" class="header-anchor">#</a> 1.VGGNet</h3> <p>它探索了卷积神经网络的深度和其性能之间的关系，通过反复的堆叠33的小型卷积核和22的最大池化层，成功的构建了16~19层深的卷积神经网络。VGGNet获得了ILSVRC 2014年比赛的亚军和定位项目的冠军，在top5上的错误率为7.5%。目前为止，VGGNet依然被用来提取图像的特征。</p> <h2 id="优缺点"><a href="#优缺点" class="header-anchor">#</a> 优缺点</h2> <p>由于参数量主要集中在最后的三个FC当中，所以网络加深并不会带来参数爆炸的问题；</p> <p>多个小核卷积层的感受野等同于一个大核卷积层（三个3x3等同于一个7x7）但是参数量远少于大核卷积层而且非线性操作也多于后者，使得其学习能力较强</p> <p>VGG由于层数多而且最后的三个全连接层参数众多，导致其占用了更多的内存（140M）</p> <h2 id="_2-resnet"><a href="#_2-resnet" class="header-anchor">#</a> 2.Resnet</h2> <p>随着深度学习的应用，各种深度学习模型随之出现，虽然在每年都会出现性能更好的新模型，但是对于前人工作的提升却不是那么明显，其中有重要问题就是深度学习网络在堆叠到一定深度的时候会出现梯度消失的现象，导致误差升高效果变差，后向传播时无法将梯度反馈到前面的网络层，使得前方的网络层的参数难以更新，训练效果变差。这个时候ResNet恰好站出来，成为深度学习发展历程中一个重要的转折点。</p> <p>ResNet语义分割领域最受欢迎且最广泛运用的神经网络.ResNet的核心思想就是在网络中引入恒等映射，允许原始输入信息直接传到后面的层中，在学习过程中可以只学习上一个网络输出的残差（F(x)），因此ResNet又叫做残差网络。</p> <p>Resnet优缺点：</p> <p>1）引入了全新的网络结构（残差学习模块），形成了新的网络结构，可以使网络尽可能地加深；</p> <p>2）使得前馈/反馈传播算法能够顺利进行，结构更加简单；</p> <p>3）恒等映射地增加基本上不会降低网络的性能；</p> <p>4）建设性地解决了网络训练的越深，误差升高，梯度消失越明显的问题；</p> <p>5）由于ResNet搭建的层数众多，所以需要的训练时间也比平常网络要长。</p> <h3 id="mask-r-cnn"><a href="#mask-r-cnn" class="header-anchor">#</a> <strong>Mask R-CNN</strong></h3> <h4 id="rcnn"><a href="#rcnn" class="header-anchor">#</a> Rcnn</h4> <p>先使用selective search算法提取2000个候选框，然后通过卷积网络对候选框进行串行的特征提取，再根据提取的特征使用SVM对候选框进行分类预测，最后使用回归方法对区域框进行修正</p> <p>R-CNN的优缺点：</p> <ul><li>是首个开创性地将深度神经网络应用到目标检测的算法；</li> <li>使用Bounding Box Regression对目标检测的框进行调整；</li> <li>由于进行特征提取时是串行，处理耗时过长；</li> <li>Selective search算法在提取每一个region时需要2s的时间，浪费大量时间</li></ul> <h4 id="fast-r-cnn"><a href="#fast-r-cnn" class="header-anchor">#</a> <strong>Fast R-CNN</strong></h4> <p>Fast R-CNN在传统的R-CNN模型上有所改进的地方是它是直接使用一个神经网络对整个图像进行特征提取，就省去了串行提取特征的时间；接着使用一个RoI Pooling Layer在全图的特征图上摘取每一个RoI对应的特征，再通过FC进行分类和包围框的修正。</p> <p><img src="https://img-blog.csdnimg.cn/20201108153439263.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwODUxNTYx,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p> <p>Fast R-CNN的优缺点</p> <ul><li>节省了串行提取特征的时间；</li> <li>除了selective search以外的其它所有模块都可以合在一起训练；</li> <li>最耗时间的selective search算法依然存在</li></ul> <h3 id="faster-r-cnn"><a href="#faster-r-cnn" class="header-anchor">#</a> <strong>Faster R-CNN</strong></h3> <p>2016年提出的Faster R-CNN可以说有了突破性的进展（虽然还是目标检测哈哈哈），因为它改变了它的前辈们最耗时最致命的部位：selective search算法。它将selective search算法替换成为RPN，使用RPN网络进行region的选取</p> <p><img src="https://img-blog.csdnimg.cn/20201108153509456.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwODUxNTYx,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p> <p>Faster R-CNN优缺点：</p> <ul><li>使用RPN替换了耗时的selective search算法，对整个网络结构有了突破性的优化；</li> <li>Faster R-CNN中使用的RPN和selective search比起来虽然速度更快，但是精度和selective search相比稍有不及，如果更注重速度而不是精度的话完全可以只使用RPN；</li></ul> <h4 id="mask-r-cnn-2"><a href="#mask-r-cnn-2" class="header-anchor">#</a> <strong>Mask R-CNN</strong></h4> <p>在Faster R-CNN的结构基础上加上了Mask预测分支，并且改良了ROI Pooling，提出了ROI Align</p> <p><img src="https://img-blog.csdnimg.cn/202011081535562.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwODUxNTYx,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p> <ul><li>引入了预测用的Mask-Head，以像素到像素的方式来预测分割掩膜，并且效果很好；</li> <li>用ROI Align替代了ROI Pooling，去除了RoI Pooling的粗量化，使得提取的特征与输入良好对齐；</li> <li>分类框与预测掩膜共享评价函数，虽然大多数时间影响不大，但是有的时候会对分割结果有所干扰。</li></ul> <h4 id="mask-scoring-r-cnn"><a href="#mask-scoring-r-cnn" class="header-anchor">#</a> <strong>Mask Scoring R-CNN</strong></h4> <p>他的网络结构也是在Mask R-CNN的网络基础上做了一点小小的改进，添加了Mask-IoU。</p> <p><img src="https://img-blog.csdnimg.cn/20201108153654798.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwODUxNTYx,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p> <ul><li>优化了Mask R-CNN中的信息传播，提高了生成预测模板的质量；</li> <li>未经大批量训练的情况下，就拿下了COCO 2017挑战赛实例分割任务冠军；</li> <li>整个网络有些庞大，一方面需要ResNet当作主干网络，另一方面需要其它各种Head共同承担各种任务。</li></ul> <h3 id="deeplab"><a href="#deeplab" class="header-anchor">#</a> DeepLab</h3> <p>主要是使用DCNNs和概率图模型（条件随机场）来实现图像像素级的分类（语义分割任务）</p> <p>DCNN应用于像素级分类任务有两大障碍：信号下采样和空间“不敏感性”（不变性）</p> <p>由于DCNNs的平移不变性，DCNNs被用到很多抽象的图像任务中，如imagenet大规模分类，coco目标检测等中。第一个问题涉及在每层DCNN上执行的最大池化和下采样（‘步长’）的重复组合所引起的信号分辨率的降，此模型通过使用空洞算法（”hole” algorithm，也叫”atrous” algorithm）来改进第一个问题，通过使用全连接条件随机场来改善分割效果。</p> <p>（1）速度快，带空洞卷积的DCNN可以达到8fps，而后处理的全连接CRF只需要0.5s。
（2）准确性高：在PASCAL VOC取得第一名的成绩，高于第二名7.2%个点，在PASCAL VOC-2012测试集上达到71.6%的IOU准确性。
（3）简单：有两个模块构成整体模型，分别是DCNN和CRF</p> <p>论文首先指出DCNNs具有空间不变性, 这样的特性十分有利于分类这种高层次的抽象决策任务(比如一张图片里边不管人在什么位置, 最后都能正确预测为人).但是对于分割或检测任务来说, DCNNs它只能够预测目标出大概的位置,不能预测出很精细的边缘细节.为什么呢?因为DCNNs中多采用卷积和max pooling的组合来提取特征以及下采样,最后得到很高级很抽象的语义特征,特别适用于分类任务.但是在这不断的下采样过程中,必然会损失掉很多空间信息,所以最后得到的小分辨率feature maps对于小目标来说,是不容检测出来的,尤其是边缘细节.</p> <h3 id="解决分辨率小的问题"><a href="#解决分辨率小的问题" class="header-anchor">#</a> 解决分辨率小的问题</h3> <p>卷积过程中就可以减少下采样的倍数(实际论文中是将pool4和pool5的stride改为1,也就是得到8x下采样feature maps之后就不下采样了,此时相当于8个输入像素计算一个特征响应),从而获得更加稠密(分辨率高)的feature maps,相当于是在高层语义特征和高分辨率之间的一个权衡折中.但是又会有问题,不做下采样的话,就会失去原先网络的大感受野</p> <h3 id="解决感受野变小的问题"><a href="#解决感受野变小的问题" class="header-anchor">#</a> 解决感受野变小的问题</h3> <p>deeplabv1从小波变换将空洞算法引入卷积网络中,空洞卷积核可以扩大卷积核的感受野.总的来说,pool4(stride=1)之后,conv5采用dialate conv(input stride或rate=2)来弥补;pool5(stride=1)之后,跟着fc6,fc7,fc8,softmax.而作者在fc6采用几种kernel size核input stride的组合来做对比实验,得到的结论是,fc6采用1024x3x3,rate=12的卷积核来全卷积连接,得到最佳表现(与fc6为4096x7x7精度相等,但更快更轻量).</p> <p>更加稠密的feature maps，意味着更多的计算量，使用空洞卷积核，一方面可以使小卷积核获得大卷积核的大感受野，另一方面，小卷积核计算更高效。</p> <p><img src="https://img-blog.csdnimg.cn/20191020141123898.png" alt="img"></p> <h3 id="另外两个亮点"><a href="#另外两个亮点" class="header-anchor">#</a> 另外两个亮点：</h3> <p>一个是针对多尺度目标的检测问题，论文作者也采用了多尺度卷积特征整合的方式,但是效果其实不明显,只有1个百分点左右的提升.大概做法是,将前4个max pool的输出经过1个128x3x3和1个128x1x1的卷积核来提取特征,并整合(concate)到pool5的输出,最终输入fc层和softmax层得到8x下采样的预测结果(训练时将gt下采样8x了),然后再将预测结果8x双线性插值上采样得到和输入尺寸一致的分割结果.</p> <p>另外一个亮点是,本文提出全连接的CRFs算法,来后处理分割结果，以得到更加精细的边缘细节.这里CRFs的提升比较明显.但这样会使得模型比较冗赘,不能够end-2-end地训练和推理,在deeplabv3之后就取消了CRFs,并且效果还更好(所以暂时先不学习这个CRFs了).</p> <h3 id="deeplabv2"><a href="#deeplabv2" class="header-anchor">#</a> DeeplabV2</h3> <p>提出ASPP模块和采用ResNet101做backbone</p> <p>空洞卷积就是在常规卷积核里边按给定的input stride(rate)填充0,从而增大了卷积核的有效视野(FOV).这样的机制可以抵消掉max pool不下采样(stride=1)带来的感受野减小的问题.</p> <p>另外,在DCNNs中减少了两次下采样,输出的feature maps尺寸相对于输入图像是下采样了8x,即得到了更加稠密(分辨率更高)同时又具备足够高级语义的feature输出,这有利于小目标和目标边缘细节的精细分割.这样做不仅考虑了目标尺度和边缘,分割精度得到明显的提升,</p> <p>而且,简化了传统DCNNs用于语义分割时冗余且低效的上采样过程.空洞卷积核并没有参数量引入额外的参数,相比传统语义分割的DCNNs少了两次上采样,速度也更快了.总的来说就是真的做到更快更精准.</p> <p><img src="https://img-blog.csdnimg.cn/20191021211039727.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2JhaWR1XzM4MjcwODQ1,size_16,color_FFFFFF,t_70" alt="img"></p> <p>空洞空间金字塔池化(ASPP)灵感来自于SPP检测网络,主要解决目标的多尺度问题.输入的feature maps为pool5的输出.假如要分割的目标在橙色框内,那么显然用大的滤波器来检测是不合适的.而往往我们也不知道使用什么样的滤波器才好,所以作者在这里设计了4种尺度的卷积核来提取目标特征,相比以往fc6层只采用单个尺度的卷积核效果好太多了.在fc层ASPP之后,将各个feature maps进行融合,得到更加有效的特征输出.论文中作者在baseline(deeplab-large-fov,1024x3x3卷积核,rate=12)基础上,分别对比了ASPP-S(rate=(2,4,8,12)),和ASPP-L(rate=(6,12,18,24))在CRFs前后的性能,结论是下图中的组合(ASPP-L)效果最好.值得一提的是,在分割网络中,空洞卷积(膨胀卷积)和ASPP模块经常被采用,可以带来性能提升.</p></div></section> <footer class="page-edit"><!----> <div class="last-updated"><span class="prefix">Last Updated: </span> <span class="time">12/9/2021, 8:18:51 PM</span></div></footer> <!----> <div class="comments-wrapper"><!----></div> <ul class="side-bar sub-sidebar-wrapper" style="width:12rem;" data-v-70334359><li class="level-2" data-v-70334359><a href="/./note/cnn/network/#cnn的五种结构" class="sidebar-link reco-side-cnn的五种结构" data-v-70334359>cnn的五种结构</a></li><li class="level-2" data-v-70334359><a href="/./note/cnn/network/#cnn与fcn的比较" class="sidebar-link reco-side-cnn与fcn的比较" data-v-70334359>CNN与FCN的比较</a></li><li class="level-2" data-v-70334359><a href="/./note/cnn/network/#fcn上采样讲解" class="sidebar-link reco-side-fcn上采样讲解" data-v-70334359>FCN上采样讲解</a></li><li class="level-3" data-v-70334359><a href="/./note/cnn/network/#_1-双线性插值上采样" class="sidebar-link reco-side-_1-双线性插值上采样" data-v-70334359>1.双线性插值上采样</a></li><li class="level-3" data-v-70334359><a href="/./note/cnn/network/#_2-反卷积上采样" class="sidebar-link reco-side-_2-反卷积上采样" data-v-70334359>2.反卷积上采样</a></li><li class="level-3" data-v-70334359><a href="/./note/cnn/network/#_3-反池化上采样" class="sidebar-link reco-side-_3-反池化上采样" data-v-70334359>3.反池化上采样</a></li><li class="level-3" data-v-70334359><a href="/./note/cnn/network/#fcn的实现" class="sidebar-link reco-side-fcn的实现" data-v-70334359>FCN的实现</a></li><li class="level-3" data-v-70334359><a href="/./note/cnn/network/#fcn的实现过程" class="sidebar-link reco-side-fcn的实现过程" data-v-70334359>FCN的实现过程</a></li><li class="level-2" data-v-70334359><a href="/./note/cnn/network/#总结" class="sidebar-link reco-side-总结" data-v-70334359>总结</a></li><li class="level-2" data-v-70334359><a href="/./note/cnn/network/#基于深度学习的分割" class="sidebar-link reco-side-基于深度学习的分割" data-v-70334359>基于深度学习的分割</a></li><li class="level-3" data-v-70334359><a href="/./note/cnn/network/#_1-vggnet" class="sidebar-link reco-side-_1-vggnet" data-v-70334359>1.VGGNet</a></li><li class="level-2" data-v-70334359><a href="/./note/cnn/network/#优缺点" class="sidebar-link reco-side-优缺点" data-v-70334359>优缺点</a></li><li class="level-2" data-v-70334359><a href="/./note/cnn/network/#_2-resnet" class="sidebar-link reco-side-_2-resnet" data-v-70334359>2.Resnet</a></li><li class="level-3" data-v-70334359><a href="/./note/cnn/network/#mask-r-cnn" class="sidebar-link reco-side-mask-r-cnn" data-v-70334359>Mask R-CNN</a></li><li class="level-3" data-v-70334359><a href="/./note/cnn/network/#faster-r-cnn" class="sidebar-link reco-side-faster-r-cnn" data-v-70334359>Faster R-CNN</a></li><li class="level-3" data-v-70334359><a href="/./note/cnn/network/#deeplab" class="sidebar-link reco-side-deeplab" data-v-70334359>DeepLab</a></li><li class="level-3" data-v-70334359><a href="/./note/cnn/network/#解决分辨率小的问题" class="sidebar-link reco-side-解决分辨率小的问题" data-v-70334359>解决分辨率小的问题</a></li><li class="level-3" data-v-70334359><a href="/./note/cnn/network/#解决感受野变小的问题" class="sidebar-link reco-side-解决感受野变小的问题" data-v-70334359>解决感受野变小的问题</a></li><li class="level-3" data-v-70334359><a href="/./note/cnn/network/#另外两个亮点" class="sidebar-link reco-side-另外两个亮点" data-v-70334359>另外两个亮点：</a></li><li class="level-3" data-v-70334359><a href="/./note/cnn/network/#deeplabv2" class="sidebar-link reco-side-deeplabv2" data-v-70334359>DeeplabV2</a></li></ul></main> <!----></div></div></div></div><div class="global-ui"><div class="back-to-ceiling" style="right:1rem;bottom:6rem;width:2.5rem;height:2.5rem;border-radius:.25rem;line-height:2.5rem;display:none;" data-v-c6073ba8 data-v-c6073ba8><svg t="1574745035067" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="5404" class="icon" data-v-c6073ba8><path d="M526.60727968 10.90185116a27.675 27.675 0 0 0-29.21455937 0c-131.36607665 82.28402758-218.69155461 228.01873535-218.69155402 394.07834331a462.20625001 462.20625001 0 0 0 5.36959153 69.94390903c1.00431239 6.55289093-0.34802892 13.13561351-3.76865779 18.80351572-32.63518765 54.11355614-51.75690182 118.55860487-51.7569018 187.94566865a371.06718723 371.06718723 0 0 0 11.50484808 91.98906777c6.53300375 25.50556257 41.68394495 28.14064038 52.69160883 4.22606766 17.37162448-37.73630017 42.14135425-72.50938081 72.80769204-103.21549295 2.18761121 3.04276886 4.15646224 6.24463696 6.40373557 9.22774369a1871.4375 1871.4375 0 0 0 140.04691725 5.34970492 1866.36093723 1866.36093723 0 0 0 140.04691723-5.34970492c2.24727335-2.98310674 4.21612437-6.18497483 6.3937923-9.2178004 30.66633723 30.70611158 55.4360664 65.4791928 72.80769147 103.21549355 11.00766384 23.91457269 46.15860503 21.27949489 52.69160879-4.22606768a371.15156223 371.15156223 0 0 0 11.514792-91.99901164c0-69.36717486-19.13165746-133.82216804-51.75690182-187.92578088-3.42062944-5.66790279-4.76302748-12.26056868-3.76865837-18.80351632a462.20625001 462.20625001 0 0 0 5.36959269-69.943909c-0.00994388-166.08943902-87.32547796-311.81420293-218.6915546-394.09823051zM605.93803103 357.87693858a93.93749974 93.93749974 0 1 1-187.89594924 6.1e-7 93.93749974 93.93749974 0 0 1 187.89594924-6.1e-7z" p-id="5405" data-v-c6073ba8></path><path d="M429.50777625 765.63860547C429.50777625 803.39355007 466.44236686 1000.39046097 512.00932183 1000.39046097c45.56695499 0 82.4922232-197.00623328 82.5015456-234.7518555 0-37.75494459-36.9345906-68.35043303-82.4922232-68.34111062-45.57627738-0.00932239-82.52019037 30.59548842-82.51086798 68.34111062z" p-id="5406" data-v-c6073ba8></path></svg></div></div></div>
    <script src="./assets/js/app.efa3ac42.js" defer></script><script src="./assets/js/3.88a32308.js" defer></script><script src="./assets/js/1.e463e428.js" defer></script><script src="./assets/js/14.b6c41929.js" defer></script>
  </body>
</html>
